"""
æ··åˆç­–ç•¥å‘é‡æ•°æ®åº“æ„å»ºå™¨
æ ¸å¿ƒæ€è·¯ï¼šç”¨ problem_decomposition å»ºç«‹ç´¢å¼•ï¼Œä½†å…ƒæ•°æ®å­˜å‚¨å®Œæ•´æ¨ç†é“¾

é€‚ç”¨åœºæ™¯ï¼š
- ç”¨æˆ·è¾“å…¥å®è§‚é—®é¢˜
- éœ€è¦ç²¾å‡†åŒ¹é…é—®é¢˜å±‚é¢
- ä½†å¸Œæœ›è·å–å®Œæ•´æ¨ç†é“¾ä½œä¸ºç”Ÿæˆå‚è€ƒ
"""

import json
import chromadb
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm
import config
from embedding_utils import QwenEmbedder


class HybridReasoningDBBuilder:
    """æ··åˆç­–ç•¥æ•°æ®åº“æ„å»ºå™¨"""
    
    def __init__(
        self,
        api_key: str,
        chroma_path: str = "./chroma_db",
        collection_name: str = "neuroscience"
    ):
        """
        åˆå§‹åŒ–æ„å»ºå™¨
        
        Args:
            api_key: Qwen API key
            chroma_path: ChromaDB æŒä¹…åŒ–è·¯å¾„
            collection_name: é›†åˆåç§°
        """
        self.embedder = QwenEmbedder(api_key=api_key)
        self.chroma_path = Path(chroma_path)
        self.collection_name = collection_name
        
        # åˆå§‹åŒ– ChromaDB
        print(f"\nåˆå§‹åŒ– ChromaDB: {self.chroma_path}")
        self.client = chromadb.PersistentClient(path=str(self.chroma_path))
        
        # è·å– embedding ç»´åº¦
        print("è·å– embedding ç»´åº¦...")
        self.embedding_dim = self.embedder.get_embedding_dimension()
        print(f"âœ“ Embedding ç»´åº¦: {self.embedding_dim}")
    
    def load_reasoning_chains(self, jsonl_file: Path) -> List[Dict]:
        """åŠ è½½æ¨ç†é“¾æ•°æ®"""
        print(f"\nåŠ è½½æ¨ç†é“¾æ•°æ®: {jsonl_file}")
        chains = []
        
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in tqdm(f, desc="è¯»å–æ•°æ®"):
                if line.strip():
                    chains.append(json.loads(line))
        
        print(f"âœ“ åŠ è½½äº† {len(chains)} æ¡æ¨ç†é“¾")
        return chains
    
    def create_collection(self, reset: bool = False):
        """åˆ›å»ºæˆ–è·å– collection"""
        if reset:
            try:
                self.client.delete_collection(name=self.collection_name)
                print(f"âœ“ å·²åˆ é™¤æ—§çš„ collection: {self.collection_name}")
            except:
                pass
        
        self.collection = self.client.get_or_create_collection(
            name=self.collection_name,
            metadata={
                "description": "æ··åˆç­–ç•¥ï¼šç”¨é—®é¢˜æ£€ç´¢ï¼Œè¿”å›å®Œæ•´æ¨ç†é“¾",
                "embedding_model": "text-embedding-v4",
                "embedding_dimension": self.embedding_dim,
                "strategy": "hybrid",
                "index_field": "problem_decomposition",
                "return_field": "full_chain"
            }
        )
        
        print(f"âœ“ Collection å·²å°±ç»ª: {self.collection_name}")
        print(f"  å½“å‰æ–‡æ¡£æ•°: {self.collection.count()}")
    
    def build_database(self, reasoning_chains: List[Dict]):
        """
        æ„å»ºæ··åˆç­–ç•¥æ•°æ®åº“
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. åªå¯¹ problem_decomposition è¿›è¡Œ embeddingï¼ˆæ£€ç´¢ç´¢å¼•ï¼‰
        2. ä½†åœ¨å…ƒæ•°æ®ä¸­å­˜å‚¨å®Œæ•´çš„æ¨ç†é“¾ï¼ˆè¿”å›å†…å®¹ï¼‰
        3. æ£€ç´¢æ—¶ç²¾å‡†åŒ¹é…é—®é¢˜ï¼Œè¿”å›æ—¶è·å¾—å®Œæ•´æ¨ç†é“¾
        """
        print(f"\nå¼€å§‹æ„å»ºå‘é‡æ•°æ®åº“...")
        print(f"ç­–ç•¥: æ··åˆç­–ç•¥ï¼ˆé—®é¢˜ç´¢å¼• + å®Œæ•´æ¨ç†é“¾å­˜å‚¨ï¼‰")
        print(f"æ€»è®ºæ–‡æ•°: {len(reasoning_chains)}")
        
        all_ids = []
        all_embeddings = []
        all_documents = []
        all_metadatas = []
        
        failed_count = 0
        
        for chain in tqdm(reasoning_chains, desc="å¤„ç†è®ºæ–‡"):
            paper_id = chain.get('paper_id', 'unknown')
            title = chain.get('title', 'Unknown Title')
            
            # æå–å››å…ƒç»„
            problem = chain.get('problem_decomposition', '')
            data = chain.get('data', '')
            method = chain.get('method', '')
            conclusion = chain.get('conclusion', '')
            
            # æ£€æŸ¥å®Œæ•´æ€§
            if not all([problem, data, method, conclusion]):
                tqdm.write(f"âš  è·³è¿‡ä¸å®Œæ•´çš„æ¨ç†é“¾: {title}")
                failed_count += 1
                continue
            
            # ğŸ”‘ å…³é”®ï¼šåªå¯¹ problem_decomposition è¿›è¡Œ embedding
            # æ„é€ æ£€ç´¢æ–‡æ¡£ï¼ˆåªåŒ…å«é—®é¢˜éƒ¨åˆ†ï¼‰
            index_text = f"""Research Title: {title}

Problem Decomposition:
{problem}"""
            
            # ç”Ÿæˆ embeddingï¼ˆåªåŸºäºé—®é¢˜ï¼‰
            embedding = self.embedder.embed_single(index_text)
            
            if embedding is None:
                tqdm.write(f"âœ— Embedding å¤±è´¥: {title}")
                failed_count += 1
                continue
            
            # ğŸ”‘ å…³é”®ï¼šåœ¨å…ƒæ•°æ®ä¸­å­˜å‚¨å®Œæ•´æ¨ç†é“¾
            reasoning_chain_dict = {
                'problem_decomposition': problem,
                'data': data,
                'method': method,
                'conclusion': conclusion
            }
            
            # å…ƒæ•°æ®ï¼ˆåŒ…å«å®Œæ•´æ¨ç†é“¾ï¼‰
            metadata = {
                'paper_id': paper_id,
                'title': title,
                'doi': chain.get('doi', ''),
                'year': chain.get('year', 0),
                'citation_count': chain.get('citation_count', 0),
                'journal': chain.get('journal', ''),
                'is_open_access': chain.get('is_open_access', False),
                # å®Œæ•´çš„æ¨ç†é“¾ï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
                'reasoning_chain': json.dumps(reasoning_chain_dict, ensure_ascii=False)
            }
            
            all_ids.append(paper_id)
            all_embeddings.append(embedding)
            all_documents.append(index_text)  # å­˜å‚¨ç´¢å¼•æ–‡æœ¬ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            all_metadatas.append(metadata)
            
            # æ‰¹é‡æ’å…¥
            if len(all_ids) >= 50:
                self.collection.add(
                    ids=all_ids,
                    embeddings=all_embeddings,
                    documents=all_documents,
                    metadatas=all_metadatas
                )
                all_ids, all_embeddings, all_documents, all_metadatas = [], [], [], []
        
        # æ’å…¥å‰©ä½™çš„
        if all_ids:
            self.collection.add(
                ids=all_ids,
                embeddings=all_embeddings,
                documents=all_documents,
                metadatas=all_metadatas
            )
        
        print(f"\nâœ“ æ„å»ºå®Œæˆï¼")
        print(f"  æˆåŠŸ: {self.collection.count()} ç¯‡è®ºæ–‡")
        print(f"  å¤±è´¥: {failed_count} ç¯‡è®ºæ–‡")
        print(f"\næ•°æ®ç»“æ„ï¼š")
        print(f"  - ç´¢å¼•å‘é‡: åŸºäº problem_decomposition")
        print(f"  - å…ƒæ•°æ®: å®Œæ•´æ¨ç†é“¾ï¼ˆ4ä¸ªå­—æ®µï¼‰")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="æ„å»ºæ··åˆç­–ç•¥å‘é‡æ•°æ®åº“ï¼ˆé—®é¢˜ç´¢å¼• + å®Œæ•´æ¨ç†é“¾ï¼‰"
    )
    parser.add_argument(
        "--input",
        type=str,
        default="data/reasoning_chains_fixed_2.jsonl",
        help="æ¨ç†é“¾ JSONL æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--chroma-path",
        type=str,
        default="./chroma_db",
        help="ChromaDB å­˜å‚¨è·¯å¾„"
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help="é‡ç½®å·²å­˜åœ¨çš„æ•°æ®åº“"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="Qwen API Key"
    )
    
    args = parser.parse_args()
    
    # è·å– API key
    api_key = args.api_key or config.OPENAI_API_KEY
    print("="*80)
    print("ç­–ç•¥è¯´æ˜ï¼š")
    print("  1. ç´¢å¼•ï¼šåªå¯¹ problem_decomposition å»ºç«‹å‘é‡ç´¢å¼•")
    print("  2. å­˜å‚¨ï¼šå…ƒæ•°æ®ä¸­ä¿å­˜å®Œæ•´çš„å››å…ƒç»„")
    print("  3. æ£€ç´¢ï¼šç”¨æˆ·é—®é¢˜ç²¾å‡†åŒ¹é… problemï¼Œé¿å…è¢«æ–¹æ³•ç¨€é‡Š")
    print("  4. è¿”å›ï¼šè·å–å®Œæ•´æ¨ç†é“¾ä½œä¸ºç”Ÿæˆå‚è€ƒ")
    print("="*80)
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = HybridReasoningDBBuilder(
        api_key=api_key,
        chroma_path=args.chroma_path
    )
    
    # åŠ è½½æ•°æ®
    chains = builder.load_reasoning_chains(Path(args.input))
    
    # åˆ›å»º collection
    builder.create_collection(reset=args.reset)
    
    # æ„å»ºæ•°æ®åº“
    builder.build_database(chains)
    
    print("\n" + "="*80)
    print("âœ“ å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
    print("="*80)
    print(f"\næ•°æ®åº“ä½ç½®: {args.chroma_path}")
    print(f"Collection åç§°: neuroscience")
    print(f"\nä¸‹ä¸€æ­¥ï¼š")
    print(f"  ä½¿ç”¨ reasoning_chain_generator.py ç”Ÿæˆæ¨ç†é“¾")
    print(f"  ï¼ˆä¿®æ”¹ chroma_path å‚æ•°ä¸º './chroma_db'ï¼‰")


if __name__ == "__main__":
    main()
